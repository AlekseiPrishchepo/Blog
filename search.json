[
  {
    "objectID": "posts/20240721-welcome/index.html",
    "href": "posts/20240721-welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome and take care!"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html",
    "href": "posts/20240731-customers-graphs/index.html",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "",
    "text": "Traditional relational databases and spreadsheets fall short in capturing complex relationships among customers. Enter graph theory – a powerful framework for representing and analyzing interconnected data. By visualizing customer relationships as a graph, we can uncover hidden patterns, identify clusters, and improve data quality."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#introduction",
    "href": "posts/20240731-customers-graphs/index.html#introduction",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "",
    "text": "Traditional relational databases and spreadsheets fall short in capturing complex relationships among customers. Enter graph theory – a powerful framework for representing and analyzing interconnected data. By visualizing customer relationships as a graph, we can uncover hidden patterns, identify clusters, and improve data quality."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#motivation",
    "href": "posts/20240731-customers-graphs/index.html#motivation",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Motivation",
    "text": "Motivation\nOver time, customers records can become fragmented and duplicated. For example, a customer may use multiple email addresses or phone numbers when interacting with a company. Creating a new record for each email or phone can lead to duplicate records for the same customer. This is especially common in B2B scenarios, where customers often have multiple representatives. Furthermore, some customers represent multiple companies, and their records may be duplicated across different companies.\nDoing any type of marketing analysis on such dataset can lead to incorrect results. We cannot be sure about the latest purchase, the total amount spent, or the number of orders. Is this customer a loyal one or not? Is that customer a new one or not? Is this customer going to leave us or they just started buying from another company? Do we need to send a discount to this customer or not? To answer these questions, we need to have customers database defragmented and deduplicated.\nMerging records manually can be time-consuming and error-prone. By using graphs, we can represent the relationships between customers, emails, and phones and find groups of connected customers. This can help us identify duplicate records and perform actions depending on our business logic."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#sample-data",
    "href": "posts/20240731-customers-graphs/index.html#sample-data",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Sample Data",
    "text": "Sample Data\nWe have three datasets: customers, emails, and phones. Each customer can have multiple emails and phones. The names, emails, and phones are generated randomly and do not correspond to real people, though the structure of the data is similar to what you might find in a real-world scenario. In fact, it is the sample taken from the real data, but the names and other personal information are generated randomly to replace the actual ones.\n\ncustomers = pd.read_csv(\"data/customers.csv\")\nemails = pd.read_csv(\"data/emails.csv\")\nphones = pd.read_csv(\"data/phones.csv\")\n\nTake a look at the data.\n\ncustomers.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nname\n\n\n\n\n0\n330087\nWilliam Sparks\n\n\n1\n443237\nJoseph Williams\n\n\n2\n329867\nEddie Porter\n\n\n\n\n\n\n\n\n\nLength: 1000 Unique: 1000\n\n\n\nemails.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nemail\n\n\n\n\n0\n599100\nbrian12@example.net\n\n\n1\n330087\nemyers@example.com\n\n\n2\n25494\ncindymurphy@example.net\n\n\n\n\n\n\n\n\n\nLength: 957 Unique: 626 Duplicated: 331 Empty: 0\n\n\n\nphones.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nphone\n\n\n\n\n0\n15962\n876.997.0254\n\n\n1\n99723\n001-706-213-0362\n\n\n2\n99723\n886.527.4420x90003\n\n\n\n\n\n\n\n\n\nLength: 855 Unique: 524 Duplicated: 331 Empty: 0"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#icons-for-nodes",
    "href": "posts/20240731-customers-graphs/index.html#icons-for-nodes",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Icons for Nodes",
    "text": "Icons for Nodes\nNext chunk of code creates a dictionary of icons for different types of nodes in the graph. It will be used later to visualize the subgraphs.\n\nimport PIL\n\nicons = {\n    \"customer\": \"icons/customer.png\",\n    \"phone\": \"icons/phone.png\",\n    \"email\": \"icons/email.png\",\n}\n\nimages = {k: PIL.Image.open(fname) for k, fname in icons.items()}"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#creating-a-graph",
    "href": "posts/20240731-customers-graphs/index.html#creating-a-graph",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Creating a Graph",
    "text": "Creating a Graph\nLet’s create graph and add nodes. Each node will represent a customer, email, or phone. We will use the images dictionary to assign an image to each node, but it’s not necessary for the procedure, as well as setting the type of the node.\n\nG = nx.Graph()\n\nnodes = []\n\nfor x in emails[\"email\"].dropna().unique():\n    G.add_node(x, image=images[\"email\"], type=\"email\")\n\nfor x in phones[\"phone\"].dropna().unique():\n    G.add_node(x, image=images[\"phone\"], type=\"phone\")\n\nfor x in customers[\"customer_id\"].unique():\n    G.add_node(x, image=images[\"customer\"], type=\"customer\")\n\nNext, we will add edges to the graph. The edges will connect customers with their emails and phones.\n\nedges = []\n\nfor x in customers[[\"customer_id\"]].merge(emails).values:\n    edges.append(x)\n\nfor x in customers[[\"customer_id\"]].merge(phones).values:\n    edges.append(x)\n\nG.add_edges_from(edges)"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#finding-groups-of-connected-customers",
    "href": "posts/20240731-customers-graphs/index.html#finding-groups-of-connected-customers",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Finding Groups of Connected Customers",
    "text": "Finding Groups of Connected Customers\nCustomers that share the same email or phone will be connected by the edges. Let’s find groups of connected customers.\n\ngroups = list(nx.connected_components(G))\nprint(\"Groups:\", len(groups))\n\nGroups: 559"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#visualizing-the-graph",
    "href": "posts/20240731-customers-graphs/index.html#visualizing-the-graph",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Visualizing the Graph",
    "text": "Visualizing the Graph\nThe number of connected components is rather large to visualize all of them, and most of the groups will contain only a few nodes. Let’s find the groups with the largest number of nodes and visualize them.\n\ndf = pd.DataFrame([groups]).T\ndf.columns = [\"group\"]\ndf[\"size\"] = df[\"group\"].apply(len)\ndf[\"size\"].hist(bins=20, log=True)\nplt.title(\"Group Size Distribution\")\nplt.show();\nplt.close()\n\n\n\n\n\n\n\n\nThe simplest way to visualize the graph is to use the draw function from the networkx library. We will use the nx.draw function to visualize the graph. We will create a grid of subplots and visualize the top groups. Parameter seed is set to 42 to make the layout reproducible.\n\nfig, axes = plt.subplots(3, 4, figsize=(8, 6))\n\ntop_groups = list(\n    df.sort_values(\n        \"size\",\n        ascending=False,\n    )\n    .head(len(axes.flatten()))\n    .index\n)\n\nfor i, g in enumerate(top_groups):\n    ax = axes.flatten()[i]\n    subgraph = G.subgraph(groups[g])\n    pos = nx.spring_layout(subgraph, seed=42)\n    nx.draw(\n        subgraph,\n        pos=pos,\n        with_labels=False,\n        node_size=25,\n        ax=ax,\n    )\n    ax.set_title(f\"Group {g}\");\n\nplt.tight_layout()\nplt.show();\nplt.close()\n\n\n\n\n\n\n\n\nThere are literally constellations of different shapes and sizes. Let’s visualize some of them in more detail."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#visualizing-subgraphs",
    "href": "posts/20240731-customers-graphs/index.html#visualizing-subgraphs",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Visualizing Subgraphs",
    "text": "Visualizing Subgraphs\nLet’s visualize one of the largest group in more detail. We will use the nx.draw_networkx_edges function to draw the edges and the imshow function to display the icons of the nodes. We will also add the customer id to the customers’ nodes. The value of parameter seed is set to the same value as in the previous chunk to keep the layout. You can change it to see different layouts.\n\nsubgraph = G.subgraph(groups[91])\nfig, ax = plt.subplots(figsize=(8, 8))\n\npos = nx.spring_layout(subgraph, seed=42)\n\nnx.draw_networkx_edges(\n    subgraph,\n    pos=pos,\n    ax=ax,\n    arrows=True,\n    arrowstyle=\"-\",\n    min_source_margin=10,\n    min_target_margin=10,\n)\n\n\ntr_figure = ax.transData.transform\ntr_axes = fig.transFigure.inverted().transform\n\n\nicon_size = (ax.get_xlim()[1] - ax.get_xlim()[0]) * 0.015\nicon_center = icon_size / 2.0\n\nfor n in subgraph.nodes:\n    xf, yf = tr_figure(pos[n])\n    xa, ya = tr_axes((xf, yf))\n    a = plt.axes([xa - icon_center, ya - icon_center, icon_size, icon_size])\n    a.imshow(subgraph.nodes[n][\"image\"])\n    if G.nodes[n][\"type\"] == \"customer\":\n        a.text(\n            0.5,\n            0.5,\n            n,\n            ha=\"center\",\n            va=\"center\",\n            fontsize=8,\n            color=\"red\",\n            backgroundcolor=\"white\",\n            bbox=dict(color=\"white\", facecolor=\"white\", alpha=0.5),\n        )\n    a.axis(\"off\")\n\nsns.despine(left=True, bottom=True)\n\nplt.show();\nplt.close()"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#why-graphs-and-not-sql",
    "href": "posts/20240731-customers-graphs/index.html#why-graphs-and-not-sql",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Why Graphs and Not SQL?",
    "text": "Why Graphs and Not SQL?\nWe can see here that the customers in this group form pretty complex relationships. A customer may be connected to another one by the phone numbers, and the other one may be connected to the third one by the email, forming a chain of connections. I believe that it is nearly impossible to find this kind of relationship using SQL. The more complex the relationships are, the more time and effort it will take to find them using SQL. For example, if we have a chain of 10 customers, where each customer is connected to the next one by the phone number, it will take 10 joins to find this chain using SQL. If we have 100 customers in the chain, it will take 100 joins to find it using SQL, and the query will probably never complete. But it takes fractions of a second to find it using the graph."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#assigning-groups-to-customers",
    "href": "posts/20240731-customers-graphs/index.html#assigning-groups-to-customers",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Assigning Groups to Customers",
    "text": "Assigning Groups to Customers\nFinally, we will assign a group to each customer. For that, we will expand the groups list and create a new DataFrame with the group_id and customer_id columns.\n\ndf = pd.DataFrame([groups]).T\ndf.columns = [\"customer_id\"]\ndf = df.explode(\"customer_id\")\ndf[\"group_id\"] = df.index\ndf.tail(3)\n\n\n\n\n\n\n\n\ncustomer_id\ngroup_id\n\n\n\n\n557\n601053\n557\n\n\n558\n571.212.7377x69843\n558\n\n\n558\n590385\n558\n\n\n\n\n\n\n\nNote that customer_id column contains phone numbers and emails as well as customer ids, but when we merge the data, there will remain only the customer ids.\n\ncustomers = customers.merge(df)\ncustomers.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nname\ngroup_id\n\n\n\n\n0\n330087\nWilliam Sparks\n1\n\n\n1\n443237\nJoseph Williams\n4\n\n\n2\n329867\nEddie Porter\n6\n\n\n\n\n\n\n\nLet’s check the number of customers and unique customer ids to make sure that we didn’t lose any customers neither we added duplicates.\n\nlen(customers), len(customers[\"customer_id\"].unique())\n\n(1000, 1000)\n\n\nLooks good. Now we can save the data to the file.\n\ncustomers.to_csv(\"data/customers_grouped.csv\", index=False)"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#conclusion",
    "href": "posts/20240731-customers-graphs/index.html#conclusion",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we explored how to merge customer records using graphs. We created a graph of customers, emails, and phones and found groups of connected customers. We assigned a group to each customer and saved the data to a file. This approach can help us identify duplicate records and perform actions depending on our business logic. We also visualized the graph and subgraphs to better understand the relationships between customers. This can be useful for marketing analysis, customer segmentation, and other tasks that require a deep understanding of customer relationships."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Constantly learning"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Business Development, Sales, and Management",
    "section": "",
    "text": "Merging Customers Records Using Graphs in Python\n\n\n\n\n\n\npython\n\n\ngraphs\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\nAleksei\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Geospatial Insights with R and rnaturalearth\n\n\n\n\n\n\nr\n\n\ngeo\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nAleksei\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nAleksei\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20240725-views-of-russia/index.html",
    "href": "posts/20240725-views-of-russia/index.html",
    "title": "Exploring Geospatial Insights with R and rnaturalearth",
    "section": "",
    "text": "The article showcases the utilization of the rnaturalearth package for handling geographical data. This package provides valuable tools and functions for working with spatial information, making it a powerful resource for data analysts and researchers interested in geographic analyses.\nToday, I stumbled upon an article discussing the approval ratings of Russia among people from various nations around the world. As I examined the list, which was sorted from worst to best, a hypothesis formed in my mind: Could the distance between this particular country and others correlate with its citizens’ approval of its international affairs? To explore this, I promptly collected data and calculated the geographical distances between the boundaries of Russia and those of the countries in the list. The null hypothesis posits that distance has no impact on approval rates, while the alternative hypothesis suggests that distance does indeed influence approval levels.\n\ntheme_set(theme_minimal())\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(admin == country)\nworld &lt;- left_join(world, df, by)\n\nworld &lt;- world[world$admin != \"Antarctica\", ]\n\nggplot(data = world) + \n  geom_sf(aes(fill = approval)) + \n  scale_fill_viridis_c(option = \"plasma\") + \n  # theme_void() +\n  theme(legend.position = \"bottom\", \n        legend.key.height = unit(5, \"pt\"), \n        legend.key.width = unit(40, \"pt\"), \n        legend.title.position = \"bottom\") + \n  labs(fill = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\n\ncountries &lt;- ne_countries(returnclass = \"sf\")\nrussia &lt;- filter(countries, grepl(\"Russia\", admin))\n\ninvisible(sf_use_s2(FALSE))\n\ndf &lt;- df |&gt; rowwise() |&gt;\n  mutate(distB = st_distance(russia, countries[countries$admin == country, ])[1])\n\ndf$distB &lt;- as.numeric(sub(\"([0-9\\\\.]+)\", \"\\\\1\", df$distB)) / 1000000\n\nmodel &lt;- lm(approval ~ distB, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ distB, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.345 -11.519  -4.029  13.302  28.339 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   22.406      3.859   5.806 1.91e-06 ***\ndistB          1.513      0.814   1.859   0.0723 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.02 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.09743,   Adjusted R-squared:  0.06922 \nF-statistic: 3.454 on 1 and 32 DF,  p-value: 0.07231\n\n\nThe model explains less than 10% of variability. P-value for distance is 0.072, so the null hypothesis cannot be rejected at the level of 0.05. Scatter plot also shows no obvious trend.\n\nqplot(df$distB, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", se = F, color = \"red\", formula = y ~ x)\n\n\n\n\n\n\n\n\nIt emerged that the geographical distance between boundaries was statistically insignificant. However, I propose an alternative hypothesis in this scenario. Russia, being an exceptionally vast country, shares proximity with Asian nations in its eastern part. Interestingly, these eastern countries exhibit a more favorable attitude toward Russia compared to their European counterparts. One plausible explanation for this discrepancy is the absence of significant Russian territorial interests in Asia. Since Moscow, the capital, lies in the western part of Russia, let’s measure the distance between capitals and explore this further using regression analysis.\n\ncities &lt;- ne_download(type = \"populated_places\", returnclass = \"sf\")\n\nReading layer `ne_110m_populated_places' from data source \n  `/tmp/Rtmp1g0rpV/ne_110m_populated_places.shp' using driver `ESRI Shapefile'\nSimple feature collection with 243 features and 137 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -175.2206 ymin: -41.29207 xmax: 179.2166 ymax: 64.14346\nGeodetic CRS:  WGS 84\n\ncapitals &lt;- cities[cities$FEATURECLA == \"Admin-0 capital\", ]\n\n\ncapitals &lt;- capitals |&gt; distinct(ADM0NAME, .keep_all = TRUE)\nmoscow &lt;- cities[cities$NAME == \"Moscow\", ]\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(country == ADM0NAME)\ndf &lt;- left_join(df, capitals, by) |&gt; select(country, approval, NAME)\n\ndf &lt;- df |&gt; rowwise() |&gt; \n  mutate(distC = st_distance(moscow, capitals[capitals$NAME == NAME, ])[1])\ndf$distC &lt;- as.numeric(sub(\"([0-9\\\\.]+)\", \"\\\\1\", df$distC)) / 1000000\n\nmodel &lt;- lm(approval ~ distC, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ distC, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-27.205 -14.005  -1.208  14.432  27.698 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  21.7485     5.1834   4.196 0.000192 ***\ndistC         0.9300     0.6958   1.337 0.190512    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.21 on 33 degrees of freedom\nMultiple R-squared:  0.05135,   Adjusted R-squared:  0.02261 \nF-statistic: 1.786 on 1 and 33 DF,  p-value: 0.1905\n\n\nUnfortunately, using the distance between capitals didn’t yield meaningful results either.\n\nqplot(df$distC, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", se = F, color = \"red\", formula = y ~ x)\n\n\n\n\n\n\n\n\nIn my search for additional regressors, I included GDP per capita,\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(country == admin)\ndf &lt;- left_join(df, countries, by) |&gt; select(country, approval, gdp_md, pop_est, economy)\n\ndf &lt;- df |&gt; mutate(gdp_pc = 1000 * gdp_md / pop_est)\n\nmodel &lt;- lm(approval ~ gdp_pc, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ gdp_pc, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.612  -6.029   1.617   4.936  22.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.26819    2.63352  16.050  &lt; 2e-16 ***\ngdp_pc      -0.67906    0.09049  -7.505 1.52e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.15 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.6377,    Adjusted R-squared:  0.6264 \nF-statistic: 56.32 on 1 and 32 DF,  p-value: 1.521e-08\n\n\nand it yielded promising results. The coefficient associated with GDP showed a remarkably low p-value of 1.52e-08, providing strong evidence against the null hypothesis. The coefficient of determination (R-squared) was also quite favorable at 0.6377, indicating that the model captures a substantial portion of the variation in approval rates. The coefficient with gdp_pc indicates that for every additional thousand USD of GDP per capita, there is a corresponding 0.7 percentage point decrease in the approval rate.\n\nqplot(df$gdp_pc, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", formula = y ~ x) + \n  labs(x = \"GDP per capita, K\", y = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\nIn an effort to enhance predictive power, one can explore the possibility of non-linear dependencies. Let’s consider using the logarithm of GDP as a predictor.\n\nmodel &lt;- lm(approval ~ log(gdp_pc), data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ log(gdp_pc), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.983  -5.332  -0.769   3.175  28.181 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   58.164      3.828  15.194 3.46e-16 ***\nlog(gdp_pc)  -12.052      1.371  -8.794 4.77e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.125 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.7073,    Adjusted R-squared:  0.6982 \nF-statistic: 77.33 on 1 and 32 DF,  p-value: 4.77e-10\n\n\nThe resulting model yields an impressive R² value of 0.7073, indicating that it explains the vast amount of the variation. Additionally, the p-value of 4.77e-10 provides the strongest evidence against the null hypothesis.\n\nqplot(log(df$gdp_pc), df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", formula = y ~ x) + \n  labs(x = \"Logarithm of GDP per capita\", y = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\nHowever, this improved model is more complex and less straightforward to explain. Allow me to attempt an interpretation: If a country’s GDP per capita is 1% lower than another country’s, it tends to have 0.12% more people who approve of Russia.\nNow that we’ve obtained the regression model, we can use it to make predictions for the remaining countries and visualize the results on a map. By assigning colors based on predicted approval rates, we’ll create an informative and visually appealing representation.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nworld &lt;- world[world$admin != \"Antarctica\", ]\n\nworld &lt;- world |&gt; mutate(gdp_pc = 1000 * gdp_md / pop_est)\n\ninvisible(na.omit(world, cols = \"gdp_pc\"))\n\npred &lt;- predict(model, world)\n\nworld &lt;- cbind(world, pred)\n\nby &lt;- join_by(admin == country)\nworld &lt;- left_join(world, df, by)\n\nworld &lt;- mutate(world, approval = coalesce(approval, pred))\n\nworld[world$admin == \"Russia\", ]$approval &lt;- NA\n\nggplot(data = world) + \n  geom_sf(aes(fill = approval)) + \n  scale_fill_viridis_c(option = \"plasma\") + \n  theme(legend.position = \"bottom\", \n        legend.key.height = unit(5, \"pt\"), \n        legend.key.width = unit(40, \"pt\"), \n        legend.title.position = \"bottom\") + \n  labs(fill = \"\")"
  }
]