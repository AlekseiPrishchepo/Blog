[
  {
    "objectID": "posts/20240721-welcome/index.html",
    "href": "posts/20240721-welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome and take care!"
  },
  {
    "objectID": "posts/20240805-kano-model/index.html",
    "href": "posts/20240805-kano-model/index.html",
    "title": "Kano Method for Prioritization of Features",
    "section": "",
    "text": "The Kano model is a theory for product development and customer satisfaction developed in the 1980s by Professor Noriaki Kano. The model classifies customer preferences into five categories: Must-be Quality, One-dimensional Quality, Attractive Quality, Indifferent Quality, and Reverse Quality. The Kano model is used to prioritize features and functionalities in product development based on customer needs and expectations."
  },
  {
    "objectID": "posts/20240805-kano-model/index.html#categories-of-the-kano-model",
    "href": "posts/20240805-kano-model/index.html#categories-of-the-kano-model",
    "title": "Kano Method for Prioritization of Features",
    "section": "Categories of the Kano Model",
    "text": "Categories of the Kano Model\nMust-be features are basic requirements that customers expect. If these features are not present in a product, customers will be dissatisfied. However, the presence of these features does not necessarily lead to customer satisfaction. Must-be Quality features are considered essential for the product.\n\nExamples: a car must have wheels, a smartphone must have a battery, a website must have a search function.\n\nOne-dimensional features are directly proportional to customer satisfaction. The more these features are present in a product, the more satisfied customers will be. These features are usually explicitly stated by customers and are easy to measure and quantify.\n\nExamples: a car with leather seats, a smartphone with a high-resolution camera, a website with fast loading times.\n\nAttractive features are unexpected features that delight customers. These features are not explicitly requested by customers but can create a positive emotional response when present. Attractive Quality features can differentiate a product from its competitors and create a competitive advantage.\n\nExamples: a car with a built-in navigation system, a smartphone with facial recognition technology, a website with personalized recommendations.\n\nIndifferent features are neither good nor bad from the customer’s perspective. Customers are indifferent to these features, and their presence or absence does not significantly impact customer satisfaction. These features are often considered “nice to have” but not essential.\n\nExamples: a car with cup holders, a smartphone with a stylus, a website with social media integration.\n\nReverse features are features that, when present, can lead to customer dissatisfaction. These features may be perceived as unnecessary or even annoying by customers. It is essential to identify and eliminate Reverse Quality features to prevent negative customer experiences.\n\nExamples: a car with uncomfortable seats, a smartphone with a short battery life, a website with intrusive pop-up ads."
  },
  {
    "objectID": "posts/20240805-kano-model/index.html#prioritizing-features-with-the-kano-model",
    "href": "posts/20240805-kano-model/index.html#prioritizing-features-with-the-kano-model",
    "title": "Kano Method for Prioritization of Features",
    "section": "Prioritizing Features with the Kano Model",
    "text": "Prioritizing Features with the Kano Model\n\n\n\n\n\n\nFigure 1: Example of a Kano diagram.\n\n\n\nWith the Kano model, prioritization of features and functionalities becomes clear and straightforward as that:\na) keep eye on the Must-be Quality features, as they are essential, b) incorporate One-dimensional Quality features to increase customer satisfaction, c) consider Attractive Quality features to create a competitive advantage; d) eliminate Reverse Quality features, and e) save resources by setting Indifferent Quality features as low priority."
  },
  {
    "objectID": "posts/20240805-kano-model/index.html#implementation-of-the-kano-analysis",
    "href": "posts/20240805-kano-model/index.html#implementation-of-the-kano-analysis",
    "title": "Kano Method for Prioritization of Features",
    "section": "Implementation of the Kano Analysis",
    "text": "Implementation of the Kano Analysis\nImplementing the Kano model involves a sequence of steps, beginning with the development of a questionnaire. For each feature, two types of questions are posed: functional and dysfunctional.\n\nThe functional question assesses respondents’ feelings when a feature is present.\nThe dysfunctional question gauges their reactions in the absence of that feature.\n\nEach question offers five possible responses, from “I like it” to “I dislike it.” Subsequently, these responses are classified into the five Kano categories.\n\n\n\n\nTable 1: Classification of answers to the Kano questionnaire.\n\n\n\n\n\n\n\n\n\n\nCategory\n\n\nDysfunctional\n1) I like it\n2) I expect it\n3) I am neutral\n4) I can tolerate it\n5) I dislike it\n\n\nFunctional\n\n\n\n\n\n\n\n\n\n1) I like it\nQuestionable\nAttractive\nAttractive\nAttractive\nOne-dimensional\n\n\n2) I expect it\nReverse\nIndifferent\nIndifferent\nIndifferent\nMust-be\n\n\n3) I am neutral\nReverse\nIndifferent\nIndifferent\nIndifferent\nMust-be\n\n\n4) I can tolerate it\nReverse\nIndifferent\nIndifferent\nIndifferent\nMust-be\n\n\n5) I dislike it\nReverse\nReverse\nReverse\nReverse\nQuestionable\n\n\n\n\n\n\n\n\n\n\nAfter the classification of responses, the next step is to calculate the satisfaction and dissatisfaction scores for each feature. The satisfaction influence score is calculated as the percentage of Attractive and One-dimensional responses relative to the total number of responses.\n\\[ \\text{Satisfaction Influence} = \\dfrac{A + O}{ A + O + M + I } \\times 100 \\%  \\tag{1}\\] The dissatisfaction influence score is calculated as the percentage of One-dimensional and Must-be responses relative to the total number of responses.\n\\[ \\text{Dissatisfaction Influence} =  - \\dfrac{O + M}{A + O + M + I} \\times 100 \\%  \\tag{2}\\]\nThe features are then plotted on a Kano diagram, with the dissatisfaction score on the x-axis and the satisfaction score on the y-axis. The features are categorized based on their position in the diagram: Attractive Quality features in the upper left quadrant, One-dimensional Quality features in the upper right quadrant, Must-be Quality features in the lower right quadrant, and Indifferent features in the lower left quadrant, as depicted in the Figure 1."
  },
  {
    "objectID": "posts/20240805-kano-model/index.html#example-implementation-of-the-kano-analysis",
    "href": "posts/20240805-kano-model/index.html#example-implementation-of-the-kano-analysis",
    "title": "Kano Method for Prioritization of Features",
    "section": "Example implementation of the Kano Analysis",
    "text": "Example implementation of the Kano Analysis\n\nConducting a Kano Survey\nFor illustrative purposes, let’s consider existing dataset with responses to a Kano questionnaire from Doing Research Online: The Kano Model project by Alex Reppel published on GitHub under the GPL-3.0 License. The dataset consists of five csv files containing responses to functional and dysfunctional questions for various features, along with demographic information about the respondents.\n\n\nExploratory Data Analysis\nLet’s explore data. The dataframe of shape (721, 39) includes an ID column, multiple columns with demographic data such as Income_us, Gender, Age, Employment, and Education, as well as responses to functional and dysfunctional questions (F1_functional, F1_dysfunctional, etc), and columns indicating the importance of certain features to the customer (F1_importance, F2_importance, etc).\n\n\n\n\n\n\n\n\nFigure 2: Histogram of respondents’ age\n\n\n\n\n\nThe customers’ age distribution is relatively balanced, with a slight skew towards younger respondents.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Income distribution\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Employment distribution\n\n\n\n\n\n\nThe income distribution is expectedly skewed to the left. The employment distribution shows that the majority of respondents are employed full-time.\nWhile customer responses might vary based on demographic data, Kano analysis does not consider the demographic characteristics of the respondents.\n\n\nAggregating Responses\nNext, we will aggregate the responses to functional and dysfunctional questions for each feature. The table below shows an example of aggregated answers for a feature with ID = F1.\n\n\n\n\nTable 2: Example of aggregated answers for a feature.\n\n\n\n\n\n\n\n\n\n\nDysfunctional\n1) I like it\n2) I expect it\n3) I am neutral\n4) I can tolerate it\n5) I dislike it\n\n\nID\nFunctional\n\n\n\n\n\n\n\n\n\nF1_\n1) I like it\n12\n10\n21\n25\n9\n\n\n2) I expect it\n6\n6\n14\n10\n3\n\n\n3) I am neutral\n15\n25\n72\n29\n2\n\n\n4) I can tolerate it\n5\n13\n12\n10\n5\n\n\n5) I dislike it\n14\n8\n4\n2\n1\n\n\n\n\n\n\n\n\n\n\n\n\nCalculating Satisfaction and Dissatisfaction Scores\nAfter aggregating the responses, we calculate the satisfaction and dissatisfaction scores for each feature using Equation 1 and Equation 2. The table below shows the qualities: Attractive (A), Indifferent (I), Must-be (M), One-dimensional (O), Questionable (Q), Reverse (R), as well as satisfaction (S) and dissatisfaction (D) scores for each feature.\n\n\n\n\nTable 3: Qualities and satisfaction and dissatisfaction scores for each feature.\n\n\n\n\n\n\n\n\n \nID\nQuestion\nA\nI\nM\nO\nQ\nR\nS\nD\n\n\n\n\n0\nF1\nIf your funds are stored in a way that does not have to be linked to your identity, how do you feel?\n17\n57\n3\n3\n4\n16\n24\n-7\n\n\n1\nF2\nIf it is easy to store funds, how do you feel?\n22\n27\n14\n30\n3\n4\n56\n-48\n\n\n2\nF3\nIf you can access your funds wherever and whenever you want, how do you feel?\n15\n18\n14\n47\n3\n3\n66\n-65\n\n\n3\nF4\nIf it is guaranteed that no one else can access your funds without your permission, how do you feel?\n5\n12\n22\n53\n4\n4\n63\n-82\n\n\n4\nF5\nIf relevant information is always easy to find, how do you feel?\n22\n34\n12\n21\n5\n6\n49\n-37\n\n\n5\nF6\nIf you can transfer funds without having to link that transaction to your name, how do you feel?\n26\n50\n2\n5\n4\n14\n38\n-8\n\n\n6\nF7\nIf it is easy to transfer funds, how do you feel?\n20\n24\n17\n34\n4\n2\n57\n-54\n\n\n7\nF8\nIf you can transfer your funds wherever and whenever you want, how do you feel?\n21\n20\n18\n35\n4\n2\n60\n-56\n\n\n8\nF9\nIf funds are transferred almost instantaneous, how do you feel?\n40\n23\n7\n22\n4\n3\n67\n-31\n\n\n9\nF10\nIf it is guaranteed that no one else can manipulate transfers you have initiated, how do you feel?\n5\n15\n25\n49\n4\n2\n58\n-79\n\n\n10\nF11\nIf relevant information on how to make transfers is always easy to find, how do you feel?\n24\n30\n10\n26\n6\n4\n56\n-40\n\n\n\n\n\n\n\n\n\n\nPlotting the Kano Diagram\nThe last step is to plot the features on a Kano diagram. The quadrant in which the feature is located indicates a Kano category. The further the from the center, the higher the influence on satisfaction or dissatisfaction.\n\n\n\n\n\n\n\n\nFigure 5: Kano diagram"
  },
  {
    "objectID": "posts/20240805-kano-model/index.html#application-of-the-kano-model",
    "href": "posts/20240805-kano-model/index.html#application-of-the-kano-model",
    "title": "Kano Method for Prioritization of Features",
    "section": "Application of the Kano Model",
    "text": "Application of the Kano Model\nThe Kano model can be applied in product development to prioritize features and functionalities based on customer needs and expectations. By categorizing features into the five Kano categories, product managers can identify which features are essential, which are nice to have, and which can create a competitive advantage.\nThe Kano model can also help product managers understand customer preferences and make informed decisions about resource allocation and product development. By focusing on Must-be Quality and One-dimensional Quality features, product managers can ensure that the product meets basic customer requirements and maximizes customer satisfaction.\nIn conclusion, the Kano model is a valuable tool for prioritizing features and functionalities in product development. By understanding customer preferences and categorizing features into the five Kano categories, product managers can create products that meet customer needs and expectations, leading to higher customer satisfaction and competitive advantage."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html",
    "href": "posts/20240731-customers-graphs/index.html",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "",
    "text": "Traditional relational databases and spreadsheets fall short in capturing complex relationships among customers. Enter graph theory – a powerful framework for representing and analyzing interconnected data. By visualizing customer relationships as a graph, we can uncover hidden patterns, identify clusters, and improve data quality."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#introduction",
    "href": "posts/20240731-customers-graphs/index.html#introduction",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "",
    "text": "Traditional relational databases and spreadsheets fall short in capturing complex relationships among customers. Enter graph theory – a powerful framework for representing and analyzing interconnected data. By visualizing customer relationships as a graph, we can uncover hidden patterns, identify clusters, and improve data quality."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#motivation",
    "href": "posts/20240731-customers-graphs/index.html#motivation",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Motivation",
    "text": "Motivation\nOver time, customers records can become fragmented and duplicated. For example, a customer may use multiple email addresses or phone numbers when interacting with a company. Creating a new record for each email or phone can lead to duplicate records for the same customer. This is especially common in B2B scenarios, where customers often have multiple representatives. Furthermore, some customers represent multiple companies, and their records may be duplicated across different companies.\nDoing any type of marketing analysis on such dataset can lead to incorrect results. We cannot be sure about the latest purchase, the total amount spent, or the number of orders. Is this customer a loyal one or not? Is that customer a new one or not? Is this customer going to leave us or they just started buying from another company? Do we need to send a discount to this customer or not? To answer these questions, we need to have customers database defragmented and deduplicated.\nMerging records manually can be time-consuming and error-prone. By using graphs, we can represent the relationships between customers, emails, and phones and find groups of connected customers. This can help us identify duplicate records and perform actions depending on our business logic."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#sample-data",
    "href": "posts/20240731-customers-graphs/index.html#sample-data",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Sample Data",
    "text": "Sample Data\nWe have three datasets: customers, emails, and phones. Each customer can have multiple emails and phones. The names, emails, and phones are generated randomly and do not correspond to real people, though the structure of the data is similar to what you might find in a real-world scenario. In fact, it is the sample taken from the real data, but the names and other personal information are generated randomly to replace the actual ones.\n\ncustomers = pd.read_csv(\"data/customers.csv\")\nemails = pd.read_csv(\"data/emails.csv\")\nphones = pd.read_csv(\"data/phones.csv\")\n\nTake a look at the data.\n\ncustomers.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nname\n\n\n\n\n0\n330087\nWilliam Sparks\n\n\n1\n443237\nJoseph Williams\n\n\n2\n329867\nEddie Porter\n\n\n\n\n\n\n\n\n\nLength: 1000 Unique: 1000\n\n\n\nemails.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nemail\n\n\n\n\n0\n599100\nbrian12@example.net\n\n\n1\n330087\nemyers@example.com\n\n\n2\n25494\ncindymurphy@example.net\n\n\n\n\n\n\n\n\n\nLength: 957 Unique: 626 Duplicated: 331 Empty: 0\n\n\n\nphones.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nphone\n\n\n\n\n0\n15962\n876.997.0254\n\n\n1\n99723\n001-706-213-0362\n\n\n2\n99723\n886.527.4420x90003\n\n\n\n\n\n\n\n\n\nLength: 855 Unique: 524 Duplicated: 331 Empty: 0"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#icons-for-nodes",
    "href": "posts/20240731-customers-graphs/index.html#icons-for-nodes",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Icons for Nodes",
    "text": "Icons for Nodes\nNext chunk of code creates a dictionary of icons for different types of nodes in the graph. It will be used later to visualize the subgraphs.\n\nimport PIL\n\nicons = {\n    \"customer\": \"icons/customer.png\",\n    \"phone\": \"icons/phone.png\",\n    \"email\": \"icons/email.png\",\n}\n\nimages = {k: PIL.Image.open(fname) for k, fname in icons.items()}"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#creating-a-graph",
    "href": "posts/20240731-customers-graphs/index.html#creating-a-graph",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Creating a Graph",
    "text": "Creating a Graph\nLet’s create graph and add nodes. Each node will represent a customer, email, or phone. We will use the images dictionary to assign an image to each node, but it’s not necessary for the procedure, as well as setting the type of the node.\n\nG = nx.Graph()\n\nnodes = []\n\nfor x in emails[\"email\"].dropna().unique():\n    G.add_node(x, image=images[\"email\"], type=\"email\")\n\nfor x in phones[\"phone\"].dropna().unique():\n    G.add_node(x, image=images[\"phone\"], type=\"phone\")\n\nfor x in customers[\"customer_id\"].unique():\n    G.add_node(x, image=images[\"customer\"], type=\"customer\")\n\nNext, we will add edges to the graph. The edges will connect customers with their emails and phones.\n\nedges = []\n\nfor x in customers[[\"customer_id\"]].merge(emails).values:\n    edges.append(x)\n\nfor x in customers[[\"customer_id\"]].merge(phones).values:\n    edges.append(x)\n\nG.add_edges_from(edges)"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#finding-groups-of-connected-customers",
    "href": "posts/20240731-customers-graphs/index.html#finding-groups-of-connected-customers",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Finding Groups of Connected Customers",
    "text": "Finding Groups of Connected Customers\nCustomers that share the same email or phone will be connected by the edges. Let’s find groups of connected customers.\n\ngroups = list(nx.connected_components(G))\nprint(\"Groups:\", len(groups))\n\nGroups: 559"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#visualizing-the-graph",
    "href": "posts/20240731-customers-graphs/index.html#visualizing-the-graph",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Visualizing the Graph",
    "text": "Visualizing the Graph\nThe number of connected components is rather large to visualize all of them, and most of the groups will contain only a few nodes. Let’s find the groups with the largest number of nodes and visualize them.\n\ndf = pd.DataFrame([groups]).T\ndf.columns = [\"group\"]\ndf[\"size\"] = df[\"group\"].apply(len)\ndf[\"size\"].hist(bins=20, log=True)\nplt.title(\"Group Size Distribution\")\nplt.show();\nplt.close()\n\n\n\n\n\n\n\n\nThe simplest way to visualize the graph is to use the draw function from the networkx library. We will use the nx.draw function to visualize the graph. We will create a grid of subplots and visualize the top groups. Parameter seed is set to 42 to make the layout reproducible.\n\nfig, axes = plt.subplots(3, 4, figsize=(8, 6))\n\ntop_groups = list(\n    df.sort_values(\n        \"size\",\n        ascending=False,\n    )\n    .head(len(axes.flatten()))\n    .index\n)\n\nfor i, g in enumerate(top_groups):\n    ax = axes.flatten()[i]\n    subgraph = G.subgraph(groups[g])\n    pos = nx.spring_layout(subgraph, seed=42)\n    nx.draw(\n        subgraph,\n        pos=pos,\n        with_labels=False,\n        node_size=25,\n        ax=ax,\n    )\n    ax.set_title(f\"Group {g}\");\n\nplt.tight_layout()\nplt.show();\nplt.close()\n\n\n\n\n\n\n\n\nThere are literally constellations of different shapes and sizes. Let’s visualize some of them in more detail."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#visualizing-subgraphs",
    "href": "posts/20240731-customers-graphs/index.html#visualizing-subgraphs",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Visualizing Subgraphs",
    "text": "Visualizing Subgraphs\nLet’s visualize one of the largest group in more detail. We will use the nx.draw_networkx_edges function to draw the edges and the imshow function to display the icons of the nodes. We will also add the customer id to the customers’ nodes. The value of parameter seed is set to the same value as in the previous chunk to keep the layout. You can change it to see different layouts.\n\nsubgraph = G.subgraph(groups[91])\nfig, ax = plt.subplots(figsize=(8, 8))\n\npos = nx.spring_layout(subgraph, seed=42)\n\nnx.draw_networkx_edges(\n    subgraph,\n    pos=pos,\n    ax=ax,\n    arrows=True,\n    arrowstyle=\"-\",\n    min_source_margin=10,\n    min_target_margin=10,\n)\n\n\ntr_figure = ax.transData.transform\ntr_axes = fig.transFigure.inverted().transform\n\n\nicon_size = (ax.get_xlim()[1] - ax.get_xlim()[0]) * 0.015\nicon_center = icon_size / 2.0\n\nfor n in subgraph.nodes:\n    xf, yf = tr_figure(pos[n])\n    xa, ya = tr_axes((xf, yf))\n    a = plt.axes([xa - icon_center, ya - icon_center, icon_size, icon_size])\n    a.imshow(subgraph.nodes[n][\"image\"])\n    if G.nodes[n][\"type\"] == \"customer\":\n        a.text(\n            0.5,\n            0.5,\n            n,\n            ha=\"center\",\n            va=\"center\",\n            fontsize=8,\n            color=\"red\",\n            backgroundcolor=\"white\",\n            bbox=dict(color=\"white\", facecolor=\"white\", alpha=0.5),\n        )\n    a.axis(\"off\")\n\nsns.despine(left=True, bottom=True)\n\nplt.show();\nplt.close()"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#why-graphs-and-not-sql",
    "href": "posts/20240731-customers-graphs/index.html#why-graphs-and-not-sql",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Why Graphs and Not SQL?",
    "text": "Why Graphs and Not SQL?\nWe can see here that the customers in this group form pretty complex relationships. A customer may be connected to another one by the phone numbers, and the other one may be connected to the third one by the email, forming a chain of connections. I believe that it is nearly impossible to find this kind of relationship using SQL. The more complex the relationships are, the more time and effort it will take to find them using SQL. For example, if we have a chain of 10 customers, where each customer is connected to the next one by the phone number, it will take 10 joins to find this chain using SQL. If we have 100 customers in the chain, it will take 100 joins to find it using SQL, and the query will probably never complete. But it takes fractions of a second to find it using the graph."
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#assigning-groups-to-customers",
    "href": "posts/20240731-customers-graphs/index.html#assigning-groups-to-customers",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Assigning Groups to Customers",
    "text": "Assigning Groups to Customers\nFinally, we will assign a group to each customer. For that, we will expand the groups list and create a new DataFrame with the group_id and customer_id columns.\n\ndf = pd.DataFrame([groups]).T\ndf.columns = [\"customer_id\"]\ndf = df.explode(\"customer_id\")\ndf[\"group_id\"] = df.index\ndf.tail(3)\n\n\n\n\n\n\n\n\ncustomer_id\ngroup_id\n\n\n\n\n557\n601053\n557\n\n\n558\n571.212.7377x69843\n558\n\n\n558\n590385\n558\n\n\n\n\n\n\n\nNote that customer_id column contains phone numbers and emails as well as customer ids, but when we merge the data, there will remain only the customer ids.\n\ncustomers = customers.merge(df)\ncustomers.head(3)\n\n\n\n\n\n\n\n\ncustomer_id\nname\ngroup_id\n\n\n\n\n0\n330087\nWilliam Sparks\n1\n\n\n1\n443237\nJoseph Williams\n4\n\n\n2\n329867\nEddie Porter\n6\n\n\n\n\n\n\n\nLet’s check the number of customers and unique customer ids to make sure that we didn’t lose any customers neither we added duplicates.\n\nlen(customers), len(customers[\"customer_id\"].unique())\n\n(1000, 1000)\n\n\nLooks good. Now we can save the data to the file.\n\ncustomers.to_csv(\"data/customers_grouped.csv\", index=False)"
  },
  {
    "objectID": "posts/20240731-customers-graphs/index.html#conclusion",
    "href": "posts/20240731-customers-graphs/index.html#conclusion",
    "title": "Merging Customers Records Using Graphs in Python",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we explored how to merge customer records using graphs. We created a graph of customers, emails, and phones and found groups of connected customers. We assigned a group to each customer and saved the data to a file. This approach can help us identify duplicate records and perform actions depending on our business logic. We also visualized the graph and subgraphs to better understand the relationships between customers. This can be useful for marketing analysis, customer segmentation, and other tasks that require a deep understanding of customer relationships."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Constantly learning"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Business Development, Sales, and Management",
    "section": "",
    "text": "Kano Method for Prioritization of Features\n\n\n\n\n\n\nmarketing\n\n\nproduct\n\n\n\n\n\n\n\n\n\nAug 5, 2024\n\n\nAleksei\n\n\n\n\n\n\n\n\n\n\n\n\nMerging Customers Records Using Graphs in Python\n\n\n\n\n\n\npython\n\n\ngraphs\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\nAleksei\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Geospatial Insights with R and rnaturalearth\n\n\n\n\n\n\nr\n\n\ngeo\n\n\n\n\n\n\n\n\n\nJul 25, 2024\n\n\nAleksei\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nAleksei\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/20240725-views-of-russia/index.html",
    "href": "posts/20240725-views-of-russia/index.html",
    "title": "Exploring Geospatial Insights with R and rnaturalearth",
    "section": "",
    "text": "The article showcases the utilization of the rnaturalearth package for handling geographical data. This package provides valuable tools and functions for working with spatial information, making it a powerful resource for data analysts and researchers interested in geographic analyses.\nToday, I stumbled upon an article discussing the approval ratings of Russia among people from various nations around the world. As I examined the list, which was sorted from worst to best, a hypothesis formed in my mind: Could the distance between this particular country and others correlate with its citizens’ approval of its international affairs? To explore this, I promptly collected data and calculated the geographical distances between the boundaries of Russia and those of the countries in the list. The null hypothesis posits that distance has no impact on approval rates, while the alternative hypothesis suggests that distance does indeed influence approval levels.\n\ntheme_set(theme_minimal())\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(admin == country)\nworld &lt;- left_join(world, df, by)\n\nworld &lt;- world[world$admin != \"Antarctica\", ]\n\nggplot(data = world) + \n  geom_sf(aes(fill = approval)) + \n  scale_fill_viridis_c(option = \"plasma\") + \n  # theme_void() +\n  theme(legend.position = \"bottom\", \n        legend.key.height = unit(5, \"pt\"), \n        legend.key.width = unit(40, \"pt\"), \n        legend.title.position = \"bottom\") + \n  labs(fill = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\n\ncountries &lt;- ne_countries(returnclass = \"sf\")\nrussia &lt;- filter(countries, grepl(\"Russia\", admin))\n\ninvisible(sf_use_s2(FALSE))\n\ndf &lt;- df |&gt; rowwise() |&gt;\n  mutate(distB = st_distance(russia, countries[countries$admin == country, ])[1])\n\ndf$distB &lt;- as.numeric(sub(\"([0-9\\\\.]+)\", \"\\\\1\", df$distB)) / 1000000\n\nmodel &lt;- lm(approval ~ distB, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ distB, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.345 -11.519  -4.029  13.302  28.339 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   22.406      3.859   5.806 1.91e-06 ***\ndistB          1.513      0.814   1.859   0.0723 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.02 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.09743,   Adjusted R-squared:  0.06922 \nF-statistic: 3.454 on 1 and 32 DF,  p-value: 0.07231\n\n\nThe model explains less than 10% of variability. P-value for distance is 0.072, so the null hypothesis cannot be rejected at the level of 0.05. Scatter plot also shows no obvious trend.\n\nqplot(df$distB, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", se = F, color = \"red\", formula = y ~ x)\n\n\n\n\n\n\n\n\nIt emerged that the geographical distance between boundaries was statistically insignificant. However, I propose an alternative hypothesis in this scenario. Russia, being an exceptionally vast country, shares proximity with Asian nations in its eastern part. Interestingly, these eastern countries exhibit a more favorable attitude toward Russia compared to their European counterparts. One plausible explanation for this discrepancy is the absence of significant Russian territorial interests in Asia. Since Moscow, the capital, lies in the western part of Russia, let’s measure the distance between capitals and explore this further using regression analysis.\n\ncities &lt;- ne_download(type = \"populated_places\", returnclass = \"sf\")\n\nReading layer `ne_110m_populated_places' from data source \n  `/tmp/Rtmp1g0rpV/ne_110m_populated_places.shp' using driver `ESRI Shapefile'\nSimple feature collection with 243 features and 137 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -175.2206 ymin: -41.29207 xmax: 179.2166 ymax: 64.14346\nGeodetic CRS:  WGS 84\n\ncapitals &lt;- cities[cities$FEATURECLA == \"Admin-0 capital\", ]\n\n\ncapitals &lt;- capitals |&gt; distinct(ADM0NAME, .keep_all = TRUE)\nmoscow &lt;- cities[cities$NAME == \"Moscow\", ]\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(country == ADM0NAME)\ndf &lt;- left_join(df, capitals, by) |&gt; select(country, approval, NAME)\n\ndf &lt;- df |&gt; rowwise() |&gt; \n  mutate(distC = st_distance(moscow, capitals[capitals$NAME == NAME, ])[1])\ndf$distC &lt;- as.numeric(sub(\"([0-9\\\\.]+)\", \"\\\\1\", df$distC)) / 1000000\n\nmodel &lt;- lm(approval ~ distC, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ distC, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-27.205 -14.005  -1.208  14.432  27.698 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  21.7485     5.1834   4.196 0.000192 ***\ndistC         0.9300     0.6958   1.337 0.190512    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.21 on 33 degrees of freedom\nMultiple R-squared:  0.05135,   Adjusted R-squared:  0.02261 \nF-statistic: 1.786 on 1 and 33 DF,  p-value: 0.1905\n\n\nUnfortunately, using the distance between capitals didn’t yield meaningful results either.\n\nqplot(df$distC, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", se = F, color = \"red\", formula = y ~ x)\n\n\n\n\n\n\n\n\nIn my search for additional regressors, I included GDP per capita,\n\ndf &lt;- read.csv(\"ViewsOfRussia2024.csv\")\n\nby &lt;- join_by(country == admin)\ndf &lt;- left_join(df, countries, by) |&gt; select(country, approval, gdp_md, pop_est, economy)\n\ndf &lt;- df |&gt; mutate(gdp_pc = 1000 * gdp_md / pop_est)\n\nmodel &lt;- lm(approval ~ gdp_pc, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ gdp_pc, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.612  -6.029   1.617   4.936  22.483 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.26819    2.63352  16.050  &lt; 2e-16 ***\ngdp_pc      -0.67906    0.09049  -7.505 1.52e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.15 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.6377,    Adjusted R-squared:  0.6264 \nF-statistic: 56.32 on 1 and 32 DF,  p-value: 1.521e-08\n\n\nand it yielded promising results. The coefficient associated with GDP showed a remarkably low p-value of 1.52e-08, providing strong evidence against the null hypothesis. The coefficient of determination (R-squared) was also quite favorable at 0.6377, indicating that the model captures a substantial portion of the variation in approval rates. The coefficient with gdp_pc indicates that for every additional thousand USD of GDP per capita, there is a corresponding 0.7 percentage point decrease in the approval rate.\n\nqplot(df$gdp_pc, df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", formula = y ~ x) + \n  labs(x = \"GDP per capita, K\", y = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\nIn an effort to enhance predictive power, one can explore the possibility of non-linear dependencies. Let’s consider using the logarithm of GDP as a predictor.\n\nmodel &lt;- lm(approval ~ log(gdp_pc), data = df)\nsummary(model)\n\n\nCall:\nlm(formula = approval ~ log(gdp_pc), data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.983  -5.332  -0.769   3.175  28.181 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   58.164      3.828  15.194 3.46e-16 ***\nlog(gdp_pc)  -12.052      1.371  -8.794 4.77e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.125 on 32 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.7073,    Adjusted R-squared:  0.6982 \nF-statistic: 77.33 on 1 and 32 DF,  p-value: 4.77e-10\n\n\nThe resulting model yields an impressive R² value of 0.7073, indicating that it explains the vast amount of the variation. Additionally, the p-value of 4.77e-10 provides the strongest evidence against the null hypothesis.\n\nqplot(log(df$gdp_pc), df$approval) + \n  geom_point() + \n  stat_smooth(method = \"lm\", formula = y ~ x) + \n  labs(x = \"Logarithm of GDP per capita\", y = \"% who have a favorable view of Russia\")\n\n\n\n\n\n\n\n\nHowever, this improved model is more complex and less straightforward to explain. Allow me to attempt an interpretation: If a country’s GDP per capita is 1% lower than another country’s, it tends to have 0.12% more people who approve of Russia.\nNow that we’ve obtained the regression model, we can use it to make predictions for the remaining countries and visualize the results on a map. By assigning colors based on predicted approval rates, we’ll create an informative and visually appealing representation.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nworld &lt;- world[world$admin != \"Antarctica\", ]\n\nworld &lt;- world |&gt; mutate(gdp_pc = 1000 * gdp_md / pop_est)\n\ninvisible(na.omit(world, cols = \"gdp_pc\"))\n\npred &lt;- predict(model, world)\n\nworld &lt;- cbind(world, pred)\n\nby &lt;- join_by(admin == country)\nworld &lt;- left_join(world, df, by)\n\nworld &lt;- mutate(world, approval = coalesce(approval, pred))\n\nworld[world$admin == \"Russia\", ]$approval &lt;- NA\n\nggplot(data = world) + \n  geom_sf(aes(fill = approval)) + \n  scale_fill_viridis_c(option = \"plasma\") + \n  theme(legend.position = \"bottom\", \n        legend.key.height = unit(5, \"pt\"), \n        legend.key.width = unit(40, \"pt\"), \n        legend.title.position = \"bottom\") + \n  labs(fill = \"\")"
  },
  {
    "objectID": "posts/20240805-kano-model/notebook.html",
    "href": "posts/20240805-kano-model/notebook.html",
    "title": "Blog",
    "section": "",
    "text": "import os\nimport pandas as pd"
  }
]